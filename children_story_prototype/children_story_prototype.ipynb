{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Have the gradio prototype working\n",
    "have the simple children's story working\n",
    "need to figure out how to take the completed graph, pass it to gradio and get the output\n",
    "    maybe a wrapper of some sort?\n",
    "    gets the editor's last story and the image url\n",
    "    gradio works on those two items\n",
    "\n",
    "    https://oaidalleapiprodscus.blob.core.windows.net/private/org-ug5ZZy0qcBdFd2KT0250yPTa/user-zvsRunXySiBLZG0NPmh96pVL/img-wy9X6lNEraVNzwWjlzdFcQ4J.png?st=2024-09-09T00%3A22%3A39Z&se=2024-09-09T02%3A22%3A39Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-09-08T22%3A16%3A28Z&ske=2024-09-09T22%3A16%3A28Z&sks=b&skv=2024-08-04&sig=1yOljxZE%2BavoJz9D26%2B0zoBe6Bf211lFWSED21p7Oiw%3D\n",
    "\n",
    "    thinking as I go through the stream, have a simple dict that holds the relevant objects\n",
    "        editors last story\n",
    "        last image generated as a url\n",
    "        pass that into gradio\n",
    "\n",
    "\n",
    "Design\n",
    "    Gradio UI Wrapper kicks off the process and displays it\n",
    "        fn: calls the invoke on the graph\n",
    "            langraph functions defined earlier and build the graph, that is invoked\n",
    "            the invoking function loops through the process and stores two key parts\n",
    "                img url\n",
    "                story text\n",
    "            the img url and story texted are returned, as defined in what gradio is expecting\n",
    "\n",
    "    only uncertain part is how to display the image from a URL which can be worked out\n",
    "        or img downloaded and displayed locally\n",
    "\n",
    "to do\n",
    "    hook up the flow part of the generate children story\n",
    "    test grabbing an image from a url and display int with gradio\n",
    "    hook everything up\n",
    "    review it\n",
    "    test it\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "from langchain_openai import OpenAI, ChatOpenAI\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "\n",
    "\n",
    "from typing import Annotated\n",
    "\n",
    "import json\n",
    "\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and the Graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Aug 2024 Story Project v0.4\"\n",
    "\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    critic_node_count: int\n",
    "    image_url_list: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "#llm = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n",
    "# alternatively define one and then bind with a prompt template\n",
    "writer_llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "editor_llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "critic_llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "artist_llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Define the prompts\n",
    "writer_prompt = '''\n",
    "    You are a creative writer. Please write a short story for children under five years old based on the following input.\n",
    "    The story should be no more than 5 - 10 sentences.\n",
    "    '''\n",
    "\n",
    "editor_prompt = '''\n",
    "    You are an editor. Please review and edit the following story for clarity, brevity, and grammar.\n",
    "    The story is for children under five years old. The story should be no more than 5 - 10 sentences.\n",
    "    '''\n",
    "\n",
    "\n",
    "# artist_prompt = PromptTemplate(\n",
    "#     input_variables=[\"image_desc\"],\n",
    "#     template=\"Based on the following short story, please return an image. The image should be appropriate for children under five years old. {image_desc}\",\n",
    "# )\n",
    "\n",
    "artist_prompt = '''\n",
    "    Based on the following short story, please return an animated image. The image should be appropriate for children under five years old. \n",
    "    Use bright engaging colors, simple shapes, and friendly characters.\n",
    "'''\n",
    "\n",
    "\n",
    "critic_prompt = '''\n",
    "    You are a literary critic of a children's story. Please provide concise feedback on the following story for children under five years old.\n",
    "    If the story is good, provide positive feedback. If the story needs improvement, provide constructive criticism and send the story back to the writer.\n",
    "    Your output should be less than 50 words.\n",
    "\n",
    "    Output your format as a JSON object with the following keys:\n",
    "        \"critic_grade\": \"good\" or \"bad\"\n",
    "        \"critic_comments\": \"Your comments here\"\n",
    "\n",
    "    Example 1:\n",
    "    {\n",
    "        \"critic_grade\": \"good\",\n",
    "        \"critic_comments\": \"I enjoyed the story. It was engaging and imaginative.\"\n",
    "    }\n",
    "\n",
    "    Example 2:\n",
    "    {\n",
    "        \"critic_grade\": \"bad\",\n",
    "        \"critic_comments': \"The story is not appropriate for young children. It is not age appropriate\"\n",
    "    }\n",
    "    '''\n",
    "\n",
    "# writer_llm = writer_prompt | llm\n",
    "# editor_llm = editor_prompt | llm\n",
    "# critic_llm = critic_prompt | llm\n",
    "#artist_llm = artist_prompt | artist_llm\n",
    "\n",
    "def writer_chatbot(state: State):\n",
    "    state[\"messages\"].append((\"system\", writer_prompt))\n",
    "\n",
    "    response = writer_llm.invoke(state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": [response]}\n",
    "    \n",
    "\n",
    "def editor_chatbot(state: State):\n",
    "    state[\"messages\"].append((\"system\", editor_prompt))\n",
    "\n",
    "    response = editor_llm.invoke(state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def artist_chatbot(state: State):\n",
    "\n",
    "    image_prompt = artist_prompt + state[\"messages\"][-1].content\n",
    "\n",
    "    state[\"messages\"].append((\"system\", image_prompt))\n",
    "    image_url = DallEAPIWrapper().run(image_prompt)\n",
    "\n",
    "    #image_url = \"asdf\"\n",
    "    state[\"image_url_list\"].append((\"system\", image_url))\n",
    "    print(image_url)\n",
    "\n",
    "    return {\"messages\":[image_url], \"image_url_list\": [image_url], }\n",
    "    \n",
    "\n",
    "\n",
    "def critic_chatbot(state: State):\n",
    "\n",
    "    state[\"messages\"].append((\"system\", critic_prompt))\n",
    "\n",
    "    response = critic_llm.invoke(state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def route_critic_decision(state: State):\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "def select_critic_next_node(state: State):\n",
    "\n",
    "    critic_grade_key = 'critic_grade'\n",
    "    critic_grade_bad = 'bad'\n",
    "    critic_grade_good = 'good'\n",
    "    critic_comments_key = 'critic_comments'\n",
    "\n",
    "    critic_decision_writer = 'writer_chatbot'\n",
    "    critic_decision_end = '__end__'\n",
    "    critic_decision = critic_decision_end\n",
    "\n",
    "    critic_node_calls = 0\n",
    "\n",
    "    if critic_node_calls > 2:\n",
    "        print(\"Warning: critic node called too many times\")\n",
    "        critic_decision = critic_decision_end\n",
    "    else:\n",
    "\n",
    "        try:\n",
    "            critic_message = state['messages'][-1]\n",
    "\n",
    "            critic_message_parsed = json.loads(critic_message.content)\n",
    "\n",
    "            if critic_grade_key in critic_message_parsed:\n",
    "                critic_grade = critic_message_parsed[critic_grade_key]\n",
    "\n",
    "                if critic_grade == critic_grade_bad:\n",
    "                    critic_decision = critic_decision_writer\n",
    "                else:\n",
    "                    critic_decision = critic_decision_end\n",
    "            else:\n",
    "                print(\"Warning: critic unable to find grade in message\")\n",
    "        except Exception:\n",
    "            print(\"Warning: critic message parsing failed\")\n",
    " \n",
    "    return critic_decision\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"writer_chatbot\", writer_chatbot)\n",
    "graph_builder.add_node(\"editor_chatbot\", editor_chatbot)\n",
    "graph_builder.add_node(\"artist_chatbot\", artist_chatbot)\n",
    "graph_builder.add_node(\"critic_chatbot\", critic_chatbot)\n",
    "graph_builder.add_node(\"critic_routing\", route_critic_decision)\n",
    "\n",
    "graph_builder.set_entry_point(\"writer_chatbot\")\n",
    "\n",
    "graph_builder.add_edge(\"writer_chatbot\", \"editor_chatbot\")\n",
    "graph_builder.add_edge(\"editor_chatbot\", \"artist_chatbot\")\n",
    "graph_builder.add_edge(\"artist_chatbot\", \"critic_chatbot\")\n",
    "graph_builder.add_edge(\"critic_chatbot\", \"critic_routing\")\n",
    "\n",
    "\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"critic_routing\",\n",
    "    select_critic_next_node,\n",
    "    {\"writer_chatbot\": \"writer_chatbot\", \"__end__\": \"__end__\"},\n",
    ")\n",
    "\n",
    "\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "    #interrupt_before=[\"editor_chatbot\"],\n",
    "    # interrupt_after=[\"critic_chatbot\"],\n",
    "    )\n",
    "\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_children_story(user_input: str):\n",
    "    '''\n",
    "\n",
    "    the invoking function loops through the process and stores two key parts\n",
    "                img url\n",
    "                story text\n",
    "            the chat response, img url and story texted are returned, as defined in what gradio is expecting\n",
    "            \n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    chat_response: str\n",
    "        Response from the chat agent\n",
    "\n",
    "    image_list: list\n",
    "        List of images\n",
    "        to do: from URL or does it have to be local?\n",
    "\n",
    "    caption_str: str\n",
    "        Caption for each image. Formatted so can tell which image is which caption\n",
    "    \n",
    "    '''\n",
    "    chat_response = \"Error\"\n",
    "    image_list = []\n",
    "    caption_str = \"\"\n",
    "\n",
    "    \n",
    "    config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "    events = graph.stream(\n",
    "        {\"messages\": (\"user\", user_input)}, config, #stream_mode=\"values\"\n",
    "    )\n",
    "    for event in events:\n",
    "        #for value in event.values():\n",
    "        for key, value in event.items():\n",
    "            #print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "            if key == \"artist_chatbot\":\n",
    "                image_url = value[\"image_url_list\"][-1]\n",
    "                message_str = f'''{key}: {image_url}'''\n",
    "                image_list.append(image_url)\n",
    "            else:\n",
    "                message_str = f'''{key}: {value[\"messages\"][-1].content}'''\n",
    "\n",
    "                if key == \"editor_chatbot\":\n",
    "                    caption_str = value[\"messages\"][-1].content\n",
    "            pprint.pprint(message_str)\n",
    "        chat_response = \"Success\"\n",
    "    \n",
    "    return chat_response, image_list, caption_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Gradio Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the Gradio interface\n",
    "with gr.Blocks() as interface:\n",
    "    gr.Markdown(\"## LLM Image Generator\\nEnter a prompt and see the generated images with captions.\")\n",
    "    prompt_input = gr.Textbox(label=\"Prompt\")\n",
    "\n",
    "    # Button to submit the prompt and get the output\n",
    "    generate_button = gr.Button(\"Generate\")\n",
    "\n",
    "    # Textbox to display the LLM's chat response\n",
    "    chat_response_box = gr.Textbox(label=\"LLM Chat Response\", lines=4)\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            image_gallery = gr.Gallery(label=\"Generated Images\", elem_id=\"image-gallery\")\n",
    "        with gr.Column():\n",
    "            caption_text = gr.Textbox(label=\"Captions\")\n",
    "\n",
    "    # Link the components together\n",
    "    generate_button.click(fn=generate_children_story, inputs=prompt_input, outputs=[chat_response_box, image_gallery, caption_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the interface\n",
    "interface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aug2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
